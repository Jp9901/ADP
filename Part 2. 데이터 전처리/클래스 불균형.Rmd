---
title: "클래스 불균형"
output: 
  md_document:
    variant: markdown_github
---

### 클래스 불균형

```{r}
library(mlbench)
data("BreastCancer")
table(BreastCancer$Class)
```

=\> maligant의 특성이 무엇인지 학습 알고리즘이 잘 배우지 않게 될 가능성이 높아진다.

클래스 불균형 해결 방법

1.  관찰 데이터가 적은 쪽에 더 큰 가중치를 주거나 or 적은 쪽을 잘못 분류했을 때 더 많은 비용을 부과
2.  업 샘플링, 다운 샘플링, SMOTE\
    ※ 학습 데이터에 위의 방법 사용, 예측/비교는 원 데이터로

#### 1. 업 샘플링

-   upSample(x, y) \# caret 패키지

```{r}
library(caret)
ups.data <- upSample(subset(BreastCancer, select = -Class), BreastCancer$Class)

table(ups.data$Class)
```

-   의사결정 나무를 통한 성능 비교

```{r}
library(rpart)
data <- BreastCancer

# raw data
if("Id" %in% colnames(data)){
data <- subset(BreastCancer, select = -Id)}

set.seed(5)
train_idx <- sample(1:nrow(BreastCancer),0.7*nrow(BreastCancer))

train.data <- data[train_idx,]
test.data <- data[-train_idx,]

m <- rpart(Class ~., data = train.data)
confusionMatrix(test.data$Class, predict(m, newdata = test.data, type='class'))


# up sampling data
train.ups <- upSample(train.data[,!(colnames(train.data) %in% 'Class')], train.data$Class)

m.ups <- rpart(Class ~., data = train.ups)
confusionMatrix(test.data$Class, predict(m.ups, newdata = test.data, type='class'))
```

#### 2. 다운 샘플링

-   downSample(x, y) \# caret 패키지

*(업샘플링과 동일하므로 생략)*

#### 3. SMOTE

SMOTE : 비율이 낮은 분류의 데이터를 만들어내는 방법

분류 개수가 적은 쪽의 기존 샘플을 통해 주변의 이웃을 고려하여 약간씩 이동시킨 점들을 추가(k 최근접 이웃 사용)

-   SMOTE(form,data, perc.over, k,perc.under) \# DMwR 패키지

    -   perc.over : 적은 쪽의 데이터를 얼마나 추가로 샘플링해야 하는지

    -   k : 고려할 최근접 이웃의 수

    -   perc.under : 많은 쪽의 데이터 중 얼마만큼의 비율을 샘플링할 것인지

⓵ 오버샘플링 수 = perc.over/100 \* n(적은 범주의 데이터 수)

⓶ 언더샘플링 수 = perc.under/100 \* 오버샘플링 수

=\> 적은 범주의 데이터 수 = n+⓵ / 많은 범주의 데이터 수 = ⓶

```{r}
remotes::install_github("cran/DMwR")
library(DMwR)

data("iris")
data <- iris[,c(1,2,5)]
data$Species <- factor(ifelse(data$Species=='setosa','rare','common'))
table(data$Species)

newData <- SMOTE(Species~., data, perc.over = 600,perc.under = 100)
table(newData$Species)
```

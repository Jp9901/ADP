### 클래스 불균형

``` r
library(mlbench) # for data
data("BreastCancer")
table(BreastCancer$Class)
```

    ## 
    ##    benign malignant 
    ##       458       241

=\> maligant의 특성이 무엇인지 학습 알고리즘이 잘 배우지 않게 될
가능성이 높아진다.

클래스 불균형 해결 방법

1.  관찰 데이터가 적은 쪽에 더 큰 가중치를 주거나 or 적은 쪽을 잘못
    분류했을 때 더 많은 비용을 부과
2.  업 샘플링, 다운 샘플링, SMOTE  
    ※ 학습 데이터에 위의 방법 사용, 예측/비교는 원 데이터로

#### 1. 업 샘플링

-   upSample(x, y) \# caret 패키지

``` r
library(caret)
```

    ## Loading required package: ggplot2

    ## Loading required package: lattice

``` r
ups.data <- upSample(subset(BreastCancer, select = -Class), BreastCancer$Class)

table(ups.data$Class)
```

    ## 
    ##    benign malignant 
    ##       458       458

-   의사결정 나무를 통한 성능 비교

``` r
library(rpart)
data <- BreastCancer

# raw data
if("Id" %in% colnames(data)){
data <- subset(BreastCancer, select = -Id)}

set.seed(5)
train_idx <- sample(1:nrow(BreastCancer),0.7*nrow(BreastCancer))

train.data <- data[train_idx,]
test.data <- data[-train_idx,]

m <- rpart(Class ~., data = train.data)
confusionMatrix(test.data$Class, predict(m, newdata = test.data, type='class'))
```

    ## Confusion Matrix and Statistics
    ## 
    ##            Reference
    ## Prediction  benign malignant
    ##   benign       128        10
    ##   malignant      5        67
    ##                                           
    ##                Accuracy : 0.9286          
    ##                  95% CI : (0.8849, 0.9595)
    ##     No Information Rate : 0.6333          
    ##     P-Value [Acc > NIR] : <2e-16          
    ##                                           
    ##                   Kappa : 0.8441          
    ##                                           
    ##  Mcnemar's Test P-Value : 0.3017          
    ##                                           
    ##             Sensitivity : 0.9624          
    ##             Specificity : 0.8701          
    ##          Pos Pred Value : 0.9275          
    ##          Neg Pred Value : 0.9306          
    ##              Prevalence : 0.6333          
    ##          Detection Rate : 0.6095          
    ##    Detection Prevalence : 0.6571          
    ##       Balanced Accuracy : 0.9163          
    ##                                           
    ##        'Positive' Class : benign          
    ## 

``` r
# up sampling data
train.ups <- upSample(train.data[,!(colnames(train.data) %in% 'Class')], train.data$Class)

m.ups <- rpart(Class ~., data = train.ups)
confusionMatrix(test.data$Class, predict(m.ups, newdata = test.data, type='class'))
```

    ## Confusion Matrix and Statistics
    ## 
    ##            Reference
    ## Prediction  benign malignant
    ##   benign       132         6
    ##   malignant      5        67
    ##                                           
    ##                Accuracy : 0.9476          
    ##                  95% CI : (0.9082, 0.9736)
    ##     No Information Rate : 0.6524          
    ##     P-Value [Acc > NIR] : <2e-16          
    ##                                           
    ##                   Kappa : 0.8841          
    ##                                           
    ##  Mcnemar's Test P-Value : 1               
    ##                                           
    ##             Sensitivity : 0.9635          
    ##             Specificity : 0.9178          
    ##          Pos Pred Value : 0.9565          
    ##          Neg Pred Value : 0.9306          
    ##              Prevalence : 0.6524          
    ##          Detection Rate : 0.6286          
    ##    Detection Prevalence : 0.6571          
    ##       Balanced Accuracy : 0.9407          
    ##                                           
    ##        'Positive' Class : benign          
    ## 

#### 2. 다운 샘플링

-   downSample(x, y) \# caret 패키지

*(업샘플링과 동일하므로 생략)*

#### 3. SMOTE

SMOTE : 비율이 낮은 분류의 데이터를 만들어내는 방법

분류 개수가 적은 쪽의 기존 샘플을 통해 주변의 이웃을 고려하여 약간씩
이동시킨 점들을 추가(k 최근접 이웃 사용)

-   SMOTE(form,data, perc.over, k,perc.under) \# DMwR 패키지

    -   perc.over : 적은 쪽의 데이터를 얼마나 추가로 샘플링해야 하는지

    -   k : 고려할 최근접 이웃의 수

    -   perc.under : 많은 쪽의 데이터 중 얼마만큼의 비율을 샘플링할
        것인지

⓵ 오버샘플링 수 = perc.over/100 \* n(적은 범주의 데이터 수)

⓶ 언더샘플링 수 = perc.under/100 \* ⓵

=\> 적은 범주의 데이터 수 = n+⓵ / 많은 범주의 데이터 수 = ⓶

``` r
remotes::install_github("cran/DMwR")
```

    ## Using GitHub PAT from the git credential store.

    ## Skipping install of 'DMwR' from a github remote, the SHA1 (6fd4f0cd) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(DMwR)
```

    ## Loading required package: grid

    ## Registered S3 method overwritten by 'quantmod':
    ##   method            from
    ##   as.zoo.data.frame zoo

``` r
data("iris")
data <- iris[,c(1,2,5)]
data$Species <- factor(ifelse(data$Species=='setosa','rare','common'))
table(data$Species)
```

    ## 
    ## common   rare 
    ##    100     50

``` r
newData <- SMOTE(Species~., data, perc.over = 600,perc.under = 100)
table(newData$Species)
```

    ## 
    ## common   rare 
    ##    300    350
